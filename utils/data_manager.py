# utils/data_manager.py
from __future__ import annotations
from pathlib import Path
from typing import List, Optional, Dict, Any
import pandas as pd
import numpy as np
import streamlit as st
import random

# ---------- ç©©å¥è·¯å¾‘ ----------
ROOT = Path(__file__).resolve().parents[1]
ASSETS = ROOT / "attached_assets"
DEFAULT_CSV = ASSETS / "attached_assets/finding move 2.csv"   # ğŸ‘ˆ æ–°è³‡æ–™è«‹ä¸Šå‚³/è¦†è“‹åˆ°é€™å€‹æª”å

# ---------- æ¬„ä½åˆ¥åï¼ˆè‡ªå‹•å°æ‡‰ï¼‰ ----------
COLUMN_ALIASES = {
    "name":        ["name", "åç¨±", "å ´åœ°åç¨±", "åœ°é»"],
    "district":    ["district", "è¡Œæ”¿å€", "å€"],
    "address":     ["address", "åœ°å€", "åœ°é»åœ°å€"],
    "sport_type":  ["sport_type", "sport", "é‹å‹•", "é‹å‹•é¡å‹"],
    "price_range": ["price_range", "åƒ¹æ ¼å€é–“", "åƒ¹æ ¼ç¯„åœ", "åƒ¹ä½"],
    "price_per_hour": ["price_per_hour", "æ¯å°æ™‚åƒ¹æ ¼", "åƒ¹æ ¼"],
    "opening_hours":["opening_hours", "ç‡Ÿæ¥­æ™‚é–“", "é–‹æ”¾æ™‚é–“"],
    "facilities":  ["facilities", "è¨­æ–½"],
    "venue_scale": ["venue_scale", "å ´åœ°è¦æ¨¡"],
    "courses":     ["courses", "èª²ç¨‹"],
    "other":       ["other", "å…¶ä»–"],
    "website":     ["website", "å®˜ç¶²", "ç¶²ç«™"],
    "contact_phone":["contact_phone", "é›»è©±", "è¯çµ¡é›»è©±"],
    "photos":      ["photos", "åœ–ç‰‡", "ç›¸ç‰‡"],
    "latitude":    ["latitude", "lat", "ç·¯åº¦"],
    "longitude":   ["longitude", "lon", "ç¶“åº¦"],
    "rating":      ["rating", "è©•åˆ†", "stars"],
    "id":          ["id", "å ´åœ°ID", "å ´é¤¨ID"],
}

# å°åŒ—å„è¡Œæ”¿å€ä¸­å¿ƒé»ï¼ˆç¼ºç·¯ç¶“æ™‚ä½¿ç”¨ï¼‰
DISTRICT_COORDS = {
    'å£«æ—å€': (25.0881, 121.5256), 'å¤§å®‰å€': (25.0266, 121.5484),
    'ä¸­å±±å€': (25.0633, 121.5267), 'å¤§åŒå€': (25.0633, 121.5154),
    'ä¸­æ­£å€': (25.0364, 121.5161), 'ä¿¡ç¾©å€': (25.0336, 121.5751),
    'è¬è¯å€': (25.0327, 121.5060), 'æ–‡å±±å€': (24.9906, 121.5420),
    'æ¾å±±å€': (25.0501, 121.5776), 'å…§æ¹–å€': (25.0838, 121.5948),
    'å—æ¸¯å€': (25.0415, 121.6073), 'åŒ—æŠ•å€': (25.1372, 121.5018)
}
DEFAULT_TAIPEI = (25.0478, 121.5319)

def _rename_by_aliases(df: pd.DataFrame) -> pd.DataFrame:
    """æŠŠä¸­è‹±/åˆ¥åæ¬„ä½å°æ‡‰åˆ°æ¨™æº–æ¬„ä½åã€‚"""
    mapping = {}
    lower_map = {c.lower(): c for c in df.columns}
    for std, aliases in COLUMN_ALIASES.items():
        for a in aliases:
            if a in df.columns:
                mapping[a] = std
                break
            if a.lower() in lower_map:
                mapping[lower_map[a.lower()]] = std
                break
    return df.rename(columns=mapping)

def _detect_header_row(csv_path: Path) -> int:
    """
    å˜—è©¦åµæ¸¬ header åœ¨ç¬¬å¹¾åˆ—ï¼ˆå›å‚³éœ€è·³éçš„åˆ—æ•¸ï¼‰ã€‚
    è¦å‰‡ï¼šæƒå‰ 10 è¡Œï¼Œæ‰¾åˆ°åŒ…å«é—œéµæ¬„ï¼ˆå¦‚ åœ°å€/address/åç¨±/nameï¼‰çš„é‚£ä¸€è¡Œã€‚
    """
    try:
        with open(csv_path, "r", encoding="utf-8-sig") as f:
            lines = [next(f) for _ in range(10)]
    except Exception:
        return 0

    keywords = ["åœ°å€", "address", "åç¨±", "name", "é‹å‹•", "sport"]
    for i, line in enumerate(lines):
        normalized = line.strip().lower()
        if any(k in normalized for k in [k.lower() for k in keywords]):
            return i  # è·³é i è¡Œ â†’ ç¬¬ i è¡Œç•¶ header
    return 0

def _normalize_sport_type(sport_type):
    if pd.isna(sport_type) or str(sport_type).strip() == "":
        return "ç¶œåˆé‹å‹•"
    s = str(sport_type).strip()
    mapping = {
        'ç¾½çƒ': 'ç¾½æ¯›çƒ', 'ç¾½æ¯›çƒ': 'ç¾½æ¯›çƒ', 'æ¸¸æ³³': 'æ¸¸æ³³', 'å¥èº«': 'å¥èº«',
        'é‡è¨“': 'å¥èº«', 'æœ‰æ°§': 'æœ‰æ°§é‹å‹•', 'ç‘œçˆ': 'ç‘œä¼½', 'ç‘œä¼½': 'ç‘œä¼½',
        'çƒé¡': 'çƒé¡é‹å‹•', 'ç±ƒçƒ': 'ç±ƒçƒ', 'è¶³çƒ': 'è¶³çƒ', 'ç¶²çƒ': 'ç¶²çƒ',
        'æ¡Œçƒ': 'æ¡Œçƒ', 'æ’çƒ': 'æ’çƒ', 'æ’çƒ': 'æ’çƒ', 'æˆ¶å¤–é‹å‹•': 'æˆ¶å¤–é‹å‹•'
    }
    for k, v in mapping.items():
        if k in s:
            return v
    # å¤šå€‹ä»¥ / åˆ†éš”æ™‚å–ç¬¬ä¸€å€‹èƒ½å°æ‡‰çš„
    if "/" in s:
        for t in [x.strip() for x in s.split("/")]:
            for k, v in mapping.items():
                if k in t:
                    return v
    return s

def _extract_price(price_range):
    if pd.isna(price_range) or str(price_range).strip() == "":
        return random.randint(100, 500)
    s = str(price_range).strip()
    if "0-200" in s:
        return 150
    if "200-500" in s:
        return 350
    if "500ä»¥ä¸Š" in s or "500+" in s:
        return 700
    # è‹¥åŸæœ¬å°±æœ‰æ•¸å­—æ¬„ä½ price_per_hourï¼Œå°±ä¸è¦†è“‹
    try:
        # e.g. "300", "NT$300"
        digits = "".join(ch for ch in s if ch.isdigit())
        if digits:
            return int(digits)
    except Exception:
        pass
    return random.randint(200, 400)

def _normalize_facilities(facilities):
    if pd.isna(facilities) or str(facilities).strip() == "":
        return "åŸºæœ¬è¨­æ–½"
    s = str(facilities).strip()
    mapping = {
        'æ·‹æµ´é–“': 'æ·‹æµ´é–“', 'ç½®ç‰©æ«ƒ': 'ç½®ç‰©æ«ƒ', 'åœè»Šå ´': 'åœè»Šå ´',
        'Wi-Fi': 'Wi-Fi', 'WiFi': 'Wi-Fi', 'ç„¡éšœç¤™è¨­æ–½': 'ç„¡éšœç¤™è¨­æ–½',
        'æ€§åˆ¥å‹å–„è¨­æ–½': 'æ€§åˆ¥å‹å–„è¨­æ–½', 'å¯µç‰©å‹å–„': 'å¯µç‰©å‹å–„', 'å¥³æ€§å°ˆç”¨': 'å¥³æ€§å°ˆç”¨'
    }
    norm = [v for k, v in mapping.items() if k in s]
    return "/".join(norm) if norm else s

def _coords_from_district(district: str) -> tuple[float, float]:
    return DISTRICT_COORDS.get(str(district).strip(), DEFAULT_TAIPEI)

@st.cache_data(show_spinner=False)
def load_venues_data(csv_path: str | Path | None = None) -> pd.DataFrame:
    """
    è®€å– CSV â†’ æ¬„ä½å°æ‡‰ â†’ æ•¸å€¼è½‰å‹ â†’ å¡«è£œåº§æ¨™/åƒ¹æ ¼/è©•åˆ†
    å°‡æ–° CSV æ”¾åœ¨ attached_assets/venues.csv å¾Œï¼Œé€™è£¡æœƒè‡ªå‹•è®€å–ã€‚
    """
    p = Path(csv_path) if csv_path else DEFAULT_CSV
    if not p.exists():
        print(f"CSV æª”æ¡ˆä¸å­˜åœ¨ï¼š{p}")
        return pd.DataFrame()

    # è‡ªå‹•åµæ¸¬ header åˆ—ï¼›å„ªå…ˆç”¨ UTF-8-SIG
    skiprows = _detect_header_row(p)
    try:
        df = pd.read_csv(p, encoding="utf-8-sig", skiprows=skiprows)
    except UnicodeDecodeError:
        df = pd.read_csv(p, encoding="utf-8", skiprows=skiprows)

    # å…ˆå°æ‡‰æ¬„ä½åï¼ˆæŠŠä¸­æ–‡/è‹±æ–‡/åˆ¥åçµ±ä¸€æˆæ¨™æº–åï¼‰
    df = _rename_by_aliases(df)

    # è‹¥ä½ çš„èˆŠæª”æœ‰å›ºå®š 13 æ¬„ï¼ˆä½ ä¹‹å‰æ‰‹å‹•å‘½åéï¼‰ï¼Œå¯åœ¨æ‰¾ä¸åˆ°æ¨™æº–åæ™‚è£œä¸Šå°æ‡‰
    fallback_cols = [
        'name','district','price_range','sport_type','opening_hours','facilities',
        'venue_scale','courses','other','website','address','contact_phone','photos'
    ]
    if set(fallback_cols).issubset(set(df.columns)) is False and len(df.columns) == 13:
        df.columns = fallback_cols

    # å»ºç«‹æ¨™æº–æ¬„ä½
    if "name" not in df.columns:
        # æ²’åå­—å°±æ²’è¾¦æ³•å‘ˆç¾ï¼Œç›´æ¥è¿”å›ç©ºè³‡æ–™
        return pd.DataFrame()

    # åŸºæœ¬æ¸…ç†
    df = df.dropna(subset=["name"])
    df = df[df["name"].astype(str).str.strip() != ""]

    # sport_type æ­£è¦åŒ–
    if "sport_type" in df.columns:
        df["sport_type"] = df["sport_type"].apply(_normalize_sport_type)
    else:
        df["sport_type"] = "ç¶œåˆé‹å‹•"

    # price_per_hour å„ªå…ˆä½¿ç”¨ç¾æœ‰æ¬„ä½ï¼Œå¦å‰‡ç”± price_range æ¨ä¼°
    if "price_per_hour" not in df.columns:
        df["price_per_hour"] = df.get("price_range", pd.Series([np.nan]*len(df))).apply(_extract_price)
    df["price_per_hour"] = pd.to_numeric(df["price_per_hour"], errors="coerce")

    # è©•åˆ†æ¬„ä½ï¼šè‹¥æ²’æœ‰å°±æ¨¡æ“¬ 3.5~5.0
    if "rating" not in df.columns:
        df["rating"] = [round(random.uniform(3.5, 5.0), 1) for _ in range(len(df))]

    # è¨­æ–½æ­£è¦åŒ–
    if "facilities" in df.columns:
        df["facilities"] = df["facilities"].apply(_normalize_facilities)
    else:
        df["facilities"] = "åŸºæœ¬è¨­æ–½"

    # å–å¾—åº§æ¨™ï¼šè‹¥ç„¡ç·¯ç¶“åº¦ï¼Œå‰‡ç”¨è¡Œæ”¿å€ä¸­å¿ƒï¼›è‹¥æœ‰ç©ºå€¼ä¹Ÿè£œä¸Š
    lat_exists = "latitude" in df.columns
    lon_exists = "longitude" in df.columns
    if not lat_exists or not lon_exists:
        coords = df["district"].apply(_coords_from_district) if "district" in df.columns else [DEFAULT_TAIPEI]*len(df)
        df["latitude"]  = [c[0] for c in coords]
        df["longitude"] = [c[1] for c in coords]
    else:
        df["latitude"]  = pd.to_numeric(df["latitude"], errors="coerce")
        df["longitude"] = pd.to_numeric(df["longitude"], errors="coerce")
        need_fill = df["latitude"].isna() | df["longitude"].isna()
        if "district" in df.columns and need_fill.any():
            coords = df.loc[need_fill, "district"].apply(_coords_from_district)
            df.loc[need_fill, "latitude"]  = [c[0] for c in coords]
            df.loc[need_fill, "longitude"] = [c[1] for c in coords]

    # å»ºç«‹ id æ¬„ï¼ˆè‹¥æ²’æœ‰ï¼‰
    if "id" not in df.columns:
        df.insert(0, "id", range(1, len(df)+1))

    # å¸¸ç”¨æ¬„ä½ç¢ºä¿å­˜åœ¨
    for col in ["opening_hours","venue_scale","courses","other","website","contact_phone","photos","address","district"]:
        if col not in df.columns:
            df[col] = ""

    # æ¬„ä½é †åºï¼ˆå¯ä¾éœ€æ±‚èª¿æ•´ï¼‰
    preferred_order = [
        "id","name","address","district","sport_type","price_per_hour","rating",
        "facilities","description","opening_hours","website","contact_phone",
        "venue_scale","courses","photos","latitude","longitude"
    ]
    if "description" not in df.columns and "other" in df.columns:
        df = df.rename(columns={"other":"description"})
    for c in preferred_order:
        if c not in df.columns:
            df[c] = np.nan
    df = df[preferred_order]

    print(f"âœ… æˆåŠŸè¼‰å…¥ {len(df)} ç­†å ´åœ°è³‡æ–™ï¼š{p}")
    return df

# ---------------- DataManager é¡åˆ¥ï¼ˆä¿ç•™ä½ çš„ APIï¼‰----------------
class DataManager:
    """è³‡æ–™ç®¡ç†é¡åˆ¥ï¼šå°å¤–ä»‹é¢ç¶­æŒç›¸å®¹ã€‚"""

    def __init__(self):
        self.venues_data = load_venues_data()  # ç›´æ¥ç”¨ä¸Šé¢çš„å‡½å¼
        self.sport_types: List[str] = []
        self.districts: List[str] = []
        self.facilities: List[str] = []
        self._extract_metadata()

    def _extract_metadata(self):
        df = self.venues_data
        if df is None or df.empty:
            self.sport_types = [
                "ç±ƒçƒ","è¶³çƒ","ç¶²çƒ","ç¾½æ¯›çƒ","æ¸¸æ³³","å¥èº«","è·‘æ­¥","æ¡Œçƒ","æ’çƒ","æ£’çƒ","ç‘œä¼½","èˆè¹ˆ"
            ]
            self.districts = list(DISTRICT_COORDS.keys())
            self.facilities = [
                "åœè»Šå ´","æ·‹æµ´é–“","æ›´è¡£å®¤","å†·æ°£","å™¨æç§Ÿå€Ÿ","é£²æ°´æ©Ÿ","ä¼‘æ¯å€","ç„¡éšœç¤™è¨­æ–½","Wi-Fi","ç½®ç‰©æ«ƒ","è§€çœ¾å¸­"
            ]
            return

        if "sport_type" in df.columns:
            self.sport_types = sorted(df["sport_type"].dropna().unique().tolist())
        if "district" in df.columns:
            self.districts = sorted(df["district"].dropna().unique().tolist())
        if "facilities" in df.columns:
            all_f = []
            for x in df["facilities"].dropna():
                s = str(x)
                all_f.extend([t.strip() for t in s.split("/") if t.strip()])
            self.facilities = sorted(list(set(all_f)))

    # å…¶é¤˜ä½ çš„æ–¹æ³•åŸºæœ¬ä¿ç•™ï¼ˆåƒ…å¾®èª¿ç”¨ self.venues_dataï¼‰ï¼š
    def get_all_venues(self) -> Optional[pd.DataFrame]:
        return self.venues_data.copy() if self.venues_data is not None else None

    def get_sport_types(self) -> List[str]:
        return self.sport_types.copy()

    def get_districts(self) -> List[str]:
        return self.districts.copy()

    def get_facilities(self) -> List[str]:
        return self.facilities.copy()

    def get_venue_stats(self) -> Dict[str, Any]:
        df = self.venues_data
        if df is None or df.empty:
            return {'total_venues': 0,'sport_types': 0,'districts': 0,'avg_price': 0}
        return {
            'total_venues': len(df),
            'sport_types': len(self.sport_types),
            'districts': len(self.districts),
            'avg_price': df['price_per_hour'].mean() if 'price_per_hour' in df.columns else 0
        }

    def search_venues(self, query: str) -> Optional[pd.DataFrame]:
        df = self.venues_data
        if df is None or df.empty or not query:
            return None
        q = str(query).lower().strip()
        cols = ['name','address','district','sport_type','facilities','description']
        mask = pd.Series([False]*len(df))
        for c in cols:
            if c in df.columns:
                mask |= df[c].astype(str).str.lower().str.contains(q, na=False)
        res = df[mask].copy()
        return res if not res.empty else None

    def get_filtered_venues(
        self,
        sport_types: Optional[List[str]] = None,
        districts: Optional[List[str]] = None,
        price_range: Optional[List[float]] = None,
        facilities: Optional[List[str]] = None,
        min_rating: float = 0.0,
        search_query: Optional[str] = None
    ) -> Optional[pd.DataFrame]:
        df = self.venues_data
        if df is None or df.empty:
            return None
        data = df.copy()
        if search_query:
            sr = self.search_venues(search_query)
            if sr is None or sr.empty:
                return None
            data = sr
        if sport_types and "sport_type" in data.columns:
            data = data[data["sport_type"].isin(sport_types)]
        if districts and "district" in data.columns:
            data = data[data["district"].isin(districts)]
        if price_range and "price_per_hour" in data.columns:
            lo, hi = price_range
            data = data[(data["price_per_hour"] >= lo) & (data["price_per_hour"] <= hi)]
        if facilities and "facilities" in data.columns:
            for f in facilities:
                data = data[data["facilities"].astype(str).str.contains(f, na=False, case=False)]
        if min_rating > 0 and "rating" in data.columns:
            data = data[data["rating"] >= min_rating]
        return data if not data.empty else None

    def get_venues_by_ids(self, venue_ids: List[Any]) -> Optional[pd.DataFrame]:
        df = self.venues_data
        if df is None or df.empty or not venue_ids:
            return None
        if "id" in df.columns:
            res = df[df["id"].isin(venue_ids)]
            return res if not res.empty else None
        return None

    def get_venue_by_id(self, venue_id: int) -> Optional[Dict[str, Any]]:
        df = self.venues_data
        if df is None or df.empty:
            return None
        hit = df[df["id"] == venue_id]
        return None if hit.empty else hit.iloc[0].to_dict()

    def get_popular_searches(self) -> List[str]:
        items: List[str] = []
        if self.sport_types:
            items.extend(self.sport_types[:5])
        if self.districts:
            items.extend(self.districts[:3])
        items.extend(["å®¤å…§", "æˆ¶å¤–", "ä¾¿å®œ", "é«˜è©•åˆ†", "åœè»Šå ´", "24å°æ™‚"])
        return items[:10]
